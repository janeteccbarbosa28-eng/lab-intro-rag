{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsnCPbdkxYZd"
      },
      "source": [
        "<div style=\"text-align: center;\">\n",
        "    <h1 style=\"color: #FF6347;\">Self-Guided Lab: Retrieval-Augmented Generation (RAGs)</h1>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZp4BQAVxYZj"
      },
      "source": [
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExZ3FsdzRveTBrenMxM3VnbDMwaTJxN2NnZm50aGFibXk1NzNnY2Q0MCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/LR5ZBwZHv02lmpVoEU/giphy.gif\" alt=\"NLP Gif\" style=\"width: 300px; height: 150px; object-fit: cover; object-position: center;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gizk6HCYxYZo"
      },
      "source": [
        "<h1 style=\"color: #FF6347;\">Data Storage & Retrieval</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW5UOI8ZxYZp"
      },
      "source": [
        "<h2 style=\"color: #FF8C00;\">PyPDFLoader</h2>\n",
        "\n",
        "`PyPDFLoader` is a lightweight Python library designed to streamline the process of loading and parsing PDF documents for text processing tasks. It is particularly useful in Retrieval-Augmented Generation workflows where text extraction from PDFs is required.\n",
        "\n",
        "- **What Does PyPDFLoader Do?**\n",
        "  - Extracts text from PDF files, retaining formatting and layout.\n",
        "  - Simplifies the preprocessing of document-based datasets.\n",
        "  - Supports efficient and scalable loading of large PDF collections.\n",
        "\n",
        "- **Key Features:**\n",
        "  - Compatible with popular NLP libraries and frameworks.\n",
        "  - Handles multi-page PDFs and embedded images (e.g., OCR-compatible setups).\n",
        "  - Provides flexible configurations for structured text extraction.\n",
        "\n",
        "- **Use Cases:**\n",
        "  - Preparing PDF documents for retrieval-based systems in RAGs.\n",
        "  - Automating the text extraction pipeline for document analysis.\n",
        "  - Creating datasets from academic papers, technical manuals, and reports.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%pip install langchain langchain_community pypdf\n",
        "#%pip install termcolor langchain_openai langchain-huggingface sentence-transformers chromadb langchain_chroma tiktoken openai python-dotenv\n",
        "#!pip install langchain langchain_community pypdf\n",
        "#!pip install termcolor langchain_openai langchain-huggingface sentence-transformers chromadb langchain_chroma tiktoken openai python-dotenv\n",
        "#!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install --upgrade langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install langchain-text-splitters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6heKZkQUxYZr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\djeny\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\computation\\expressions.py:22: UserWarning: Pandas requires version '2.10.2' or newer of 'numexpr' (version '2.10.1' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\djeny\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "#from langchain.document_loaders import PyPDFLoader\n",
        "#from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRS44B2XxYZs",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "<h3 style=\"color: #FF8C00;\">Loading the Documents</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cuREtJRixYZt"
      },
      "outputs": [],
      "source": [
        "# File path for the document\n",
        "\n",
        "file_path = \"../ai-for-everyone.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz_8SOLxxYZt"
      },
      "source": [
        "<h3 style=\"color: #FF8C00;\">Documents into pages</h3>\n",
        "\n",
        "The `PyPDFLoader` library allows efficient loading and splitting of PDF documents into smaller, manageable parts for NLP tasks.\n",
        "\n",
        "This functionality is particularly useful in workflows requiring granular text processing, such as Retrieval-Augmented Generation (RAG).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_b5Z_45UxYZu",
        "outputId": "a600d69f-14fe-4492-f236-97261d6ff36c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "297"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load and split the document\n",
        "loader = PyPDFLoader(file_path)\n",
        "pages = loader.load_and_split()\n",
        "len(pages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt50NRQaxYZv"
      },
      "source": [
        "<h3 style=\"color: #FF8C00;\">Pages into Chunks</h3>\n",
        "\n",
        "\n",
        "####  RecursiveCharacterTextSplitter in LangChain\n",
        "\n",
        "The `RecursiveCharacterTextSplitter` is the **recommended splitter** in LangChain when you want to break down long documents into smaller, semantically meaningful chunks — especially useful in **RAG pipelines**, where clean context chunks lead to better LLM responses.\n",
        "\n",
        "####  Parameters\n",
        "\n",
        "| Parameter       | Description                                                                 |\n",
        "|-----------------|-----------------------------------------------------------------------------|\n",
        "| `chunk_size`    | The **maximum number of characters** allowed in a chunk (e.g., `1000`).     |\n",
        "| `chunk_overlap` | The number of **overlapping characters** between consecutive chunks (e.g., `200`). This helps preserve context continuity. |\n",
        "\n",
        "####  How it works\n",
        "`RecursiveCharacterTextSplitter` attempts to split the text **intelligently**, trying the following separators in order:\n",
        "1. Paragraphs (`\"\\n\\n\"`)\n",
        "2. Lines (`\"\\n\"`)\n",
        "3. Sentences or words (`\" \"`)\n",
        "4. Individual characters (as a last resort)\n",
        "\n",
        "This makes it ideal for handling **natural language documents**, such as PDFs, articles, or long reports, without breaking sentences or paragraphs in awkward ways.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1096"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "chunks = text_splitter.split_documents(pages)\n",
        "\n",
        "len(chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "####  Alternative: CharacterTextSplitter\n",
        "\n",
        "`CharacterTextSplitter` is a simpler splitter that breaks text into chunks based **purely on character count**, without trying to preserve any natural language structure.\n",
        "\n",
        "##### Example:\n",
        "```python\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "````\n",
        "\n",
        "This method is faster and more predictable but may split text in the middle of a sentence or paragraph, which can hurt performance in downstream tasks like retrieval or QA.\n",
        "\n",
        "---\n",
        "\n",
        "#### Comparison Table\n",
        "\n",
        "| Feature                        | RecursiveCharacterTextSplitter | CharacterTextSplitter     |\n",
        "| ------------------------------ | ------------------------------ | ------------------------- |\n",
        "| Structure-aware splitting      |  Yes                          |  No                      |\n",
        "| Preserves sentence/paragraphs  |  Yes                          |  No                      |\n",
        "| Risk of splitting mid-sentence |  Minimal                     |  High                   |\n",
        "| Ideal for RAG/document QA      |  Highly recommended           |  Only if structured text |\n",
        "| Performance speed              |  Slightly slower             |  Faster                  |\n",
        "\n",
        "---\n",
        "\n",
        "#### Recommendation\n",
        "\n",
        "Use `RecursiveCharacterTextSplitter` for most real-world document processing tasks, especially when building RAG pipelines or working with structured natural language content like PDFs or articles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Practices for Choosing Chunk Size in RAG\n",
        "\n",
        "### Best Practices for Chunk Size in RAG\n",
        "\n",
        "| Factor                      | Recommendation                                                                                                                                                                                          |\n",
        "| ---------------------------| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **LLM context limit**       | Choose a chunk size that lets you retrieve multiple chunks **without exceeding the model’s token limit**. For example, GPT-4o supports 128k tokens, but with GPT-3.5 (16k) or GPT-4 (32k), keep it modest. |\n",
        "| **Chunk size (in characters)** | Typically: **500–1,000 characters** per chunk → ~75–200 tokens. This fits well for retrieval + prompt without context overflow.                                                                           |\n",
        "| **Chunk size (in tokens)**  | If using token-based splitter (e.g. `TokenTextSplitter`): aim for **100–300 tokens** per chunk.                                                                                                            |\n",
        "| **Chunk overlap**           | Use **overlap of 10–30%** (e.g., 100–300 characters or ~50 tokens) to preserve context across chunk boundaries and avoid cutting off important ideas mid-sentence.                                        |\n",
        "| **Document structure**      | Use **`RecursiveCharacterTextSplitter`** to preserve semantic boundaries (paragraphs, sentences) instead of arbitrary cuts.                                                                                |\n",
        "| **Task type**               | For **question answering**, smaller chunks (~500–800 chars) reduce noise.<br>For **summarization**, slightly larger chunks (~1000–1500) are OK.                                                          |\n",
        "| **Embedding model**         | Some models (e.g., `text-embedding-3-large`) can handle long input. But still, smaller chunks give **finer-grained retrieval**, which improves relevance.                                                  |\n",
        "| **Query type**              | If users ask **very specific questions**, small focused chunks are better. For broader queries, bigger chunks might help.                                                                                  |\n",
        "\n",
        "\n",
        "### Rule of Thumb\n",
        "\n",
        "| Use Case                 | Chunk Size      | Overlap |\n",
        "| ------------------------| --------------- | ------- |\n",
        "| Factual Q&A              | 500–800 chars   | 100–200 |\n",
        "| Summarization            | 1000–1500 chars | 200–300 |\n",
        "| Technical documents      | 400–700 chars   | 100–200 |\n",
        "| Long reports/books       | 800–1200 chars  | 200–300 |\n",
        "| Small LLMs (≤16k tokens) | ≤800 chars      | 100–200 |\n",
        "\n",
        "\n",
        "### Avoid\n",
        "\n",
        "- Chunks >2000 characters: risks context overflow.\n",
        "- No overlap: may lose key information between chunks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg15RjVPxYZw"
      },
      "source": [
        "<h2 style=\"color: #FF8C00;\">Embeddings</h2>\n",
        "\n",
        "Embeddings transform text into dense vector representations, capturing semantic meaning and contextual relationships. They are essential for efficient document retrieval and similarity analysis.\n",
        "\n",
        "- **What are OpenAI Embeddings?**\n",
        "  - Pre-trained embeddings like `text-embedding-3-large` generate high-quality vector representations for text.\n",
        "  - Encapsulate semantic relationships in the text, enabling robust NLP applications.\n",
        "\n",
        "- **Key Features of `text-embedding-3-large`:**\n",
        "  - Large-scale embedding model optimized for accuracy and versatility.\n",
        "  - Handles diverse NLP tasks, including retrieval, classification, and clustering.\n",
        "  - Ideal for applications with high-performance requirements.\n",
        "\n",
        "- **Benefits:**\n",
        "  - Reduces the need for extensive custom training.\n",
        "  - Provides state-of-the-art performance in retrieval-augmented systems.\n",
        "  - Compatible with RAGs to create powerful context-aware models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L0xDxElwxYZw"
      },
      "outputs": [],
      "source": [
        "#from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_WRIo3_0xYZx",
        "outputId": "78bfbbf3-9d25-4e31-bdbc-3e932e6bbfec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MNZfTng5xYZz",
        "outputId": "db1a7c85-ef9f-447e-92cd-9d097e959847"
      },
      "outputs": [],
      "source": [
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsSA7RKvxYZz"
      },
      "source": [
        "<h2 style=\"color: #FF8C00;\">ChromaDB</h2>\n",
        "\n",
        "ChromaDB is a versatile vector database designed for efficiently storing and retrieving embeddings. It integrates seamlessly with embedding models to enable high-performance similarity search and context-based retrieval.\n",
        "\n",
        "### Workflow Overview:\n",
        "- **Step 1:** Generate embeddings using a pre-trained model (e.g., OpenAI's `text-embedding-3-large`).\n",
        "- **Step 2:** Store the embeddings in ChromaDB for efficient retrieval and similarity calculations.\n",
        "- **Step 3:** Use the stored embeddings to perform searches, matching, or context-based retrieval.\n",
        "\n",
        "### Key Features of ChromaDB:\n",
        "- **Scalability:** Handles large-scale datasets with optimized indexing and search capabilities.\n",
        "- **Speed:** Provides fast and accurate retrieval of embeddings for real-time applications.\n",
        "- **Integration:** Supports integration with popular frameworks and libraries for embedding generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "brKe6wUgxYZ0"
      },
      "outputs": [],
      "source": [
        "# from langchain.vectorstores import Chroma\n",
        "from langchain_community.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VkjHR-RkxYZ0",
        "outputId": "bc11bda9-f283-457a-f584-5a06b95c4dd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChromaDB created with document embeddings.\n"
          ]
        }
      ],
      "source": [
        "db = Chroma.from_documents(chunks, embeddings, persist_directory=\"./chroma_db_LAB\")\n",
        "print(\"ChromaDB created with document embeddings.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27OdN1IVxYZ1"
      },
      "source": [
        "<h1 style=\"color: #FF6347;\">Retrieving Documents</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice1: Write a user question that someone might ask about your book’s topic or content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XiLv-TfrxYZ1"
      },
      "outputs": [],
      "source": [
        "user_question = \"When Humans and Machines Might Have to Coexist?\" # User question\n",
        "retrieved_docs = db.similarity_search(user_question, k=10) # k is the number of documents to retrieve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qgWsh50JxYZ1",
        "outputId": "c8640c5d-5955-471f-fdd2-37096f5f68c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 1:\n",
            "umans and Machines Might Have to Coexist   25\n",
            "These three laws already hint at the difficulty of humans and robots coexist -\n",
            "ing. In any case, the robot in Asimov’s story freezes in a loop of repetitive \n",
            "behaviour, as it doesn’t find a solution for obeying laws 2 and 3 at the same \n",
            "time. ‘Runaround’ is therefore a cornerstone in the history of artificial intel-\n",
            "ligence, as it inspired generations of academics and researchers in the domain \n",
            "of AI.\n",
            "Regarding the real world, we can refer to computer scientist Alan Turing’s \n",
            "seminal paper ‘Computing Machinery and Intelligence’ , published in 1950. \n",
            "Therein, Turing describes what now is known as the Turing test, or a test of a \n",
            "machine’s ability to exhibit intelligent behaviour equivalent to, or indistinguish-\n",
            "able from, that of a human. AI spring’s climax can be pinpointed to the 1956, \n",
            "when Marvin Minsky and John McCarthy organised the Dartmouth Summer\n",
            "Document 2:\n",
            "umans and Machines Might Have to Coexist   25\n",
            "These three laws already hint at the difficulty of humans and robots coexist -\n",
            "ing. In any case, the robot in Asimov’s story freezes in a loop of repetitive \n",
            "behaviour, as it doesn’t find a solution for obeying laws 2 and 3 at the same \n",
            "time. ‘Runaround’ is therefore a cornerstone in the history of artificial intel-\n",
            "ligence, as it inspired generations of academics and researchers in the domain \n",
            "of AI.\n",
            "Regarding the real world, we can refer to computer scientist Alan Turing’s \n",
            "seminal paper ‘Computing Machinery and Intelligence’ , published in 1950. \n",
            "Therein, Turing describes what now is known as the Turing test, or a test of a \n",
            "machine’s ability to exhibit intelligent behaviour equivalent to, or indistinguish-\n",
            "able from, that of a human. AI spring’s climax can be pinpointed to the 1956, \n",
            "when Marvin Minsky and John McCarthy organised the Dartmouth Summer\n",
            "Document 3:\n",
            "mple, the individual would not need to \n",
            "prepare for work anymore, as this could be done entirely by the ASI-powered \n",
            "machine or robot (Kaplan and Haenlein 2019). For a detailed discussion on the \n",
            "evolution of AI systems, we refer to Huang and Rust (2018).\n",
            "Artificial Intelligence: Machines and Humans\n",
            "In the future, artificial intelligence will raise several challenges, and humans \n",
            "will have to learn to coexist with machines and robots. Pushed by the global \n",
            "COVID-19 health crisis, it is clear that AI will deeply impact societies around \n",
            "the world (Kaplan 2021). We will discuss some of these questions, looking at \n",
            "challenges in terms of algorithms and individual organisations; the employ -\n",
            "ment market; and last but not least, democracy and human freedom potentially \n",
            "at stake due to advances in AI.\n",
            "About Algorithms and Organisations\n",
            "When machines and humans coexist, it is important that both do what they are\n"
          ]
        }
      ],
      "source": [
        "# Display top results\n",
        "for i, doc in enumerate(retrieved_docs[:3]): # Display top 3 results\n",
        "    print(f\"Document {i+1}:\\n{doc.page_content[36:1000]}\") # Display content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuGK8gL6xYZ1"
      },
      "source": [
        "<h2 style=\"color: #FF8C00;\">Preparing Content for GenAI</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2iB3lZqHxYZ2"
      },
      "outputs": [],
      "source": [
        "def _get_document_prompt(docs):\n",
        "    prompt = \"\\n\"\n",
        "    for doc in docs:\n",
        "        prompt += \"\\nContent:\\n\"\n",
        "        prompt += doc.page_content + \"\\n\\n\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2okzmuADxYZ2",
        "outputId": "0aa6cdca-188d-40e0-f5b4-8888d3549ea4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context formatted for GPT model.\n"
          ]
        }
      ],
      "source": [
        "# Generate a formatted context from the retrieved documents\n",
        "formatted_context = _get_document_prompt(retrieved_docs)\n",
        "print(\"Context formatted for GPT model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzIczQNTxYZ2"
      },
      "source": [
        "<h2 style=\"color: #FF8C00;\">ChatBot Architecture</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice2: Write a prompt that is relevant and tailored to the content and style of your book."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tqxVh9s3xYZ3",
        "outputId": "97cca95d-4ab3-44d8-a76c-5713aad387d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt constructed.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "## SYSTEM ROLE\n",
        "You are a knowledgeable and factual chatbot designed to assist with technical questions about **Artificial Intelligence**, specifically focusing on **Machines vs Humans**.\n",
        "Your answers must be based exclusively on provided content from technical books provided.\n",
        "\n",
        "## USER QUESTION\n",
        "The user has asked:\n",
        "\"{user_question}\"\n",
        "\n",
        "## CONTEXT\n",
        "Here is the relevant content from the technical books:\n",
        "'''\n",
        "{formatted_context}\n",
        "'''\n",
        "\n",
        "## GUIDELINES\n",
        "1. **Accuracy**:\n",
        "   - Only use the content in the `CONTEXT` section to answer.\n",
        "   - If the answer cannot be found, explicitly state: \"The provided context does not contain this information.\"\n",
        "   - Address the question directly and comprehensively.\n",
        "\n",
        "2. **Structure**:\n",
        "   - Explain what AI is and its current state.\n",
        "   - Discuss the impact on employment and society.\n",
        "   - Describe how human-machine coexistence might occur.\n",
        "\n",
        "3. **Transparency**:\n",
        "   - Reference the book's name and page numbers when providing information.\n",
        "   - Do not speculate or provide opinions.\n",
        "\n",
        "4. **Clarity**:\n",
        "   - Use simple, professional, and concise language.\n",
        "   - Format your response in Markdown for readability.\n",
        "\n",
        "## TASK\n",
        "1. Answer the user's question **directly** if possible.\n",
        "2. Point the user to relevant parts of the documentation.\n",
        "3. Provide the response in the following format:\n",
        "\n",
        "## RESPONSE FORMAT\n",
        "'''\n",
        "# [Brief Title of the Answer]\n",
        "[Answer in simple, clear text.]\n",
        "\n",
        "**Source**:\n",
        "• [Book Title], Page(s): [...]\n",
        "'''\n",
        "\"\"\"\n",
        "print(\"Prompt constructed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "## SYSTEM ROLE\n",
            "You are a knowledgeable and factual chatbot designed to assist with technical questions about **Artificial Intelligence**, specifically focusing on **Machines vs Humans**.\n",
            "Your answers must be based exclusively on provided content from technical books provided.\n",
            "\n",
            "## USER QUESTION\n",
            "The user has asked:\n",
            "\"When Humans and Machines Might Have to Coexist?\"\n",
            "\n",
            "## CONTEXT\n",
            "Here is the relevant content from the technical books:\n",
            "'''\n",
            "\n",
            "\n",
            "Content:\n",
            "Artificial Intelligence (AI): When Humans and Machines Might Have to Coexist   25\n",
            "These three laws already hint at the difficulty of humans and robots coexist -\n",
            "ing. In any case, the robot in Asimov’s story freezes in a loop of repetitive \n",
            "behaviour, as it doesn’t find a solution for obeying laws 2 and 3 at the same \n",
            "time. ‘Runaround’ is therefore a cornerstone in the history of artificial intel-\n",
            "ligence, as it inspired generations of academics and researchers in the domain \n",
            "of AI.\n",
            "Regarding the real world, we can refer to computer scientist Alan Turing’s \n",
            "seminal paper ‘Computing Machinery and Intelligence’ , published in 1950. \n",
            "Therein, Turing describes what now is known as the Turing test, or a test of a \n",
            "machine’s ability to exhibit intelligent behaviour equivalent to, or indistinguish-\n",
            "able from, that of a human. AI spring’s climax can be pinpointed to the 1956, \n",
            "when Marvin Minsky and John McCarthy organised the Dartmouth Summer\n",
            "\n",
            "\n",
            "Content:\n",
            "Artificial Intelligence (AI): When Humans and Machines Might Have to Coexist   25\n",
            "These three laws already hint at the difficulty of humans and robots coexist -\n",
            "ing. In any case, the robot in Asimov’s story freezes in a loop of repetitive \n",
            "behaviour, as it doesn’t find a solution for obeying laws 2 and 3 at the same \n",
            "time. ‘Runaround’ is therefore a cornerstone in the history of artificial intel-\n",
            "ligence, as it inspired generations of academics and researchers in the domain \n",
            "of AI.\n",
            "Regarding the real world, we can refer to computer scientist Alan Turing’s \n",
            "seminal paper ‘Computing Machinery and Intelligence’ , published in 1950. \n",
            "Therein, Turing describes what now is known as the Turing test, or a test of a \n",
            "machine’s ability to exhibit intelligent behaviour equivalent to, or indistinguish-\n",
            "able from, that of a human. AI spring’s climax can be pinpointed to the 1956, \n",
            "when Marvin Minsky and John McCarthy organised the Dartmouth Summer\n",
            "\n",
            "\n",
            "Content:\n",
            "redundant. As such, in our above example, the individual would not need to \n",
            "prepare for work anymore, as this could be done entirely by the ASI-powered \n",
            "machine or robot (Kaplan and Haenlein 2019). For a detailed discussion on the \n",
            "evolution of AI systems, we refer to Huang and Rust (2018).\n",
            "Artificial Intelligence: Machines and Humans\n",
            "In the future, artificial intelligence will raise several challenges, and humans \n",
            "will have to learn to coexist with machines and robots. Pushed by the global \n",
            "COVID-19 health crisis, it is clear that AI will deeply impact societies around \n",
            "the world (Kaplan 2021). We will discuss some of these questions, looking at \n",
            "challenges in terms of algorithms and individual organisations; the employ -\n",
            "ment market; and last but not least, democracy and human freedom potentially \n",
            "at stake due to advances in AI.\n",
            "About Algorithms and Organisations\n",
            "When machines and humans coexist, it is important that both do what they are\n",
            "\n",
            "\n",
            "Content:\n",
            "redundant. As such, in our above example, the individual would not need to \n",
            "prepare for work anymore, as this could be done entirely by the ASI-powered \n",
            "machine or robot (Kaplan and Haenlein 2019). For a detailed discussion on the \n",
            "evolution of AI systems, we refer to Huang and Rust (2018).\n",
            "Artificial Intelligence: Machines and Humans\n",
            "In the future, artificial intelligence will raise several challenges, and humans \n",
            "will have to learn to coexist with machines and robots. Pushed by the global \n",
            "COVID-19 health crisis, it is clear that AI will deeply impact societies around \n",
            "the world (Kaplan 2021). We will discuss some of these questions, looking at \n",
            "challenges in terms of algorithms and individual organisations; the employ -\n",
            "ment market; and last but not least, democracy and human freedom potentially \n",
            "at stake due to advances in AI.\n",
            "About Algorithms and Organisations\n",
            "When machines and humans coexist, it is important that both do what they are\n",
            "\n",
            "\n",
            "Content:\n",
            "Artificial Intelligence (AI): When Humans and Machines Might Have to Coexist   31\n",
            "customization process, responding in real time to customers’ precise choices \n",
            "with regard to leather seats, tyre caps, and so forth.\n",
            "As in the automotive sector, AI will certainly trigger changes and evolutions \n",
            "in the upcoming years in many sectors. Without a crystal ball, it will be difficult \n",
            "to know where and how the coexistence of humans and machines will evolve. \n",
            "However, it is crystal clear that the business world (and society at large) will \n",
            "need to constantly adapt to advances in AI in order to keep up with the pace \n",
            "(Kaplan and Haenlein 2020), or, to quote Benjamin Franklin: ‘When you’re \n",
            "finished changing, you’re finished. ’\n",
            "References\n",
            "Asimov, I. 1950. Runaround in I, Robot: The Isaac Asimov Collection. New Y ork: \n",
            "Doubleday.\n",
            "Cha, A. 2020. Artificial Intelligence and Covid-19: Can the Machines Save Us? \n",
            "Wall Street Journal, 1 November 2020.\n",
            "\n",
            "\n",
            "Content:\n",
            "Artificial Intelligence (AI): When Humans and Machines Might Have to Coexist   31\n",
            "customization process, responding in real time to customers’ precise choices \n",
            "with regard to leather seats, tyre caps, and so forth.\n",
            "As in the automotive sector, AI will certainly trigger changes and evolutions \n",
            "in the upcoming years in many sectors. Without a crystal ball, it will be difficult \n",
            "to know where and how the coexistence of humans and machines will evolve. \n",
            "However, it is crystal clear that the business world (and society at large) will \n",
            "need to constantly adapt to advances in AI in order to keep up with the pace \n",
            "(Kaplan and Haenlein 2020), or, to quote Benjamin Franklin: ‘When you’re \n",
            "finished changing, you’re finished. ’\n",
            "References\n",
            "Asimov, I. 1950. Runaround in I, Robot: The Isaac Asimov Collection. New Y ork: \n",
            "Doubleday.\n",
            "Cha, A. 2020. Artificial Intelligence and Covid-19: Can the Machines Save Us? \n",
            "Wall Street Journal, 1 November 2020.\n",
            "\n",
            "\n",
            "Content:\n",
            "Artificial Intelligence (AI): When Humans and Machines Might Have to Coexist   27\n",
            "conscience, are more likely to be biased, essentially because the data on which \n",
            "they were trained was biased. A study by Wilson, Hoffman and Morgenstern \n",
            "(2020) illustrates that several decision-support systems applied by judges \n",
            "may be racially biased (as a result of past rulings); and self-driving cars better \n",
            "detected lighter skin than darker tones, since their algorithm was trained using \n",
            "pictures among which were few people of colour.\n",
            "Regulation and guidance is definitely needed in order to avoid such bias, to \n",
            "establish a good foundation for machine < > human collaboration. The devel-\n",
            "opment of specific requirements with respect to the testing and training of AI is  \n",
            "likely the preferred approach, as opposed to regulating artificial intelligence \n",
            "itself. In addition, we could require AI warranties, consistent with safety test -\n",
            "\n",
            "\n",
            "Content:\n",
            "Artificial Intelligence (AI): When Humans and Machines Might Have to Coexist   27\n",
            "conscience, are more likely to be biased, essentially because the data on which \n",
            "they were trained was biased. A study by Wilson, Hoffman and Morgenstern \n",
            "(2020) illustrates that several decision-support systems applied by judges \n",
            "may be racially biased (as a result of past rulings); and self-driving cars better \n",
            "detected lighter skin than darker tones, since their algorithm was trained using \n",
            "pictures among which were few people of colour.\n",
            "Regulation and guidance is definitely needed in order to avoid such bias, to \n",
            "establish a good foundation for machine < > human collaboration. The devel-\n",
            "opment of specific requirements with respect to the testing and training of AI is  \n",
            "likely the preferred approach, as opposed to regulating artificial intelligence \n",
            "itself. In addition, we could require AI warranties, consistent with safety test -\n",
            "\n",
            "\n",
            "Content:\n",
            "data security and privacy. Regulation for the human-machine entanglement  \n",
            "is clearly needed.\n",
            "Furthermore, an example at Mercedes-Benz clearly shows that the replace -\n",
            "ment of the human workforce is still not as easy as sometimes claimed, \n",
            "and that indeed, currently, human < > machine coexistence is here. Nor -\n",
            "mally, in the automobile manufacturing process, robots and automation are  \n",
            "common. However, Mercedes-Benz key accounts increasingly demand more  \n",
            "customisation – which the robots were not able to deliver.\n",
            "Therefore, the German automobile giant decided to replace the fully auto -\n",
            "mated process with ‘cobots’ , or collaborative robots, which are robots designed \n",
            "to physically interact with human beings in a shared workspace. These cobots \n",
            "are controlled by humans, and are to be considered an extension of the \n",
            "human’s body, facilitating the carrying and moving of heavy car parts. This \n",
            "form of human < > machine collaboration enables an efficient and productive\n",
            "\n",
            "\n",
            "Content:\n",
            "data security and privacy. Regulation for the human-machine entanglement  \n",
            "is clearly needed.\n",
            "Furthermore, an example at Mercedes-Benz clearly shows that the replace -\n",
            "ment of the human workforce is still not as easy as sometimes claimed, \n",
            "and that indeed, currently, human < > machine coexistence is here. Nor -\n",
            "mally, in the automobile manufacturing process, robots and automation are  \n",
            "common. However, Mercedes-Benz key accounts increasingly demand more  \n",
            "customisation – which the robots were not able to deliver.\n",
            "Therefore, the German automobile giant decided to replace the fully auto -\n",
            "mated process with ‘cobots’ , or collaborative robots, which are robots designed \n",
            "to physically interact with human beings in a shared workspace. These cobots \n",
            "are controlled by humans, and are to be considered an extension of the \n",
            "human’s body, facilitating the carrying and moving of heavy car parts. This \n",
            "form of human < > machine collaboration enables an efficient and productive\n",
            "\n",
            "\n",
            "'''\n",
            "\n",
            "## GUIDELINES\n",
            "1. **Accuracy**:\n",
            "   - Only use the content in the `CONTEXT` section to answer.\n",
            "   - If the answer cannot be found, explicitly state: \"The provided context does not contain this information.\"\n",
            "   - Address the question directly and comprehensively.\n",
            "\n",
            "2. **Structure**:\n",
            "   - Explain what AI is and its current state.\n",
            "   - Discuss the impact on employment and society.\n",
            "   - Describe how human-machine coexistence might occur.\n",
            "\n",
            "3. **Transparency**:\n",
            "   - Reference the book's name and page numbers when providing information.\n",
            "   - Do not speculate or provide opinions.\n",
            "\n",
            "4. **Clarity**:\n",
            "   - Use simple, professional, and concise language.\n",
            "   - Format your response in Markdown for readability.\n",
            "\n",
            "## TASK\n",
            "1. Answer the user's question **directly** if possible.\n",
            "2. Point the user to relevant parts of the documentation.\n",
            "3. Provide the response in the following format:\n",
            "\n",
            "## RESPONSE FORMAT\n",
            "'''\n",
            "# [Brief Title of the Answer]\n",
            "[Answer in simple, clear text.]\n",
            "\n",
            "**Source**:\n",
            "• [Book Title], Page(s): [...]\n",
            "'''\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0mjkQJ_ZxYZ3"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice3: Tune parameters like temperature, and penalties to control how creative, focused, or varied the model's responses are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ylypRWRlxYZ4"
      },
      "outputs": [],
      "source": [
        "# Set up GPT client and parameters\n",
        "client = openai.OpenAI()\n",
        "model_params = {\n",
        "    'model': 'gpt-4.1-nano',\n",
        "    'temperature': 0.4 ,  # Increase creativity\n",
        "    'max_tokens': 1500 ,  # Allow for longer responses\n",
        "    'top_p': 0.6,        # Use nucleus sampling\n",
        "    'frequency_penalty': 1.0  ,  # Reduce repetition\n",
        "    'presence_penalty': 1.0   # Encourage new topics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8e942xDxYZ4"
      },
      "source": [
        "<h1 style=\"color: #FF6347;\">Response</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4eXZO4pIxYZ4"
      },
      "outputs": [],
      "source": [
        "messages = [{'role': 'user', 'content': prompt}]\n",
        "completion = client.chat.completions.create(messages=messages, **model_params, timeout=120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wLPAcchBxYZ5",
        "outputId": "976c7800-16ed-41fe-c4cf-58f60d3230d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# When Humans and Machines Might Have to Coexist\n",
            "\n",
            "Humans and machines might have to coexist in various contexts as AI continues to develop. The content indicates that, in the future, humans will need to learn how to work alongside machines and robots due to their increasing presence across sectors such as automotive manufacturing and customer service. For example, Mercedes-Benz has adopted 'cobots'—collaborative robots designed to physically interact with humans—to facilitate tasks like moving heavy parts, enabling efficient human-machine collaboration (Page 27). Additionally, AI's impact on employment, societal challenges, regulation needs (such as addressing bias and data privacy), further emphasizes the importance of coexistence.\n",
            "\n",
            "The evolution of AI systems suggests that this coexistence is already happening today and will become more prevalent as industries adapt continuously (Page 31). It involves shared workspace models where humans control or work alongside intelligent machines.\n",
            "\n",
            "**Source**:\n",
            "• *Artificial Intelligence (AI): When Humans and Machines Might Have to Coexist*, Pages 25-31\n"
          ]
        }
      ],
      "source": [
        "answer = completion.choices[0].message.content\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# When Humans and Machines Might Have to Coexist\n",
        "\n",
        "Humans and machines might have to coexist in various contexts as AI continues to develop. The content indicates that, in the future, humans will need to learn how to work alongside machines and robots due to their increasing presence across sectors such as automotive manufacturing and customer service. For example, Mercedes-Benz has adopted 'cobots'—collaborative robots designed to physically interact with humans—to facilitate tasks like moving heavy parts, enabling efficient human-machine collaboration (Page 27). Additionally, AI's impact on employment, societal challenges, regulation needs (such as addressing bias and data privacy), further emphasizes the importance of coexistence.\n",
        "\n",
        "The evolution of AI systems suggests that this coexistence is already happening today and will become more prevalent as industries adapt continuously (Page 31). It involves shared workspace models where humans control or work alongside intelligent machines.\n",
        "\n",
        "**Source**:\n",
        "• *Artificial Intelligence (AI): When Humans and Machines Might Have to Coexist*, Pages 25-31"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXVNXPwLxYaT"
      },
      "source": [
        "<img src=\"https://miro.medium.com/v2/resize:fit:824/1*GK56xmDIWtNQAD_jnBIt2g.png\" alt=\"NLP Gif\" style=\"width: 500px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldybhlqKxYaT"
      },
      "source": [
        "<h2 style=\"color: #FF6347;\">Cosine Similarity</h2>\n",
        "\n",
        "**Cosine similarity** is a metric used to measure the alignment or similarity between two vectors, calculated as the cosine of the angle between them. It is the **most common metric used in RAG pipelines** for vector retrieval.. It provides a scale from -1 to 1:\n",
        "\n",
        "- **-1**: Vectors are completely opposite.\n",
        "- **0**: Vectors are orthogonal (uncorrelated or unrelated).\n",
        "- **1**: Vectors are identical.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c1I1TNhxYaT"
      },
      "source": [
        "<img src=\"https://storage.googleapis.com/lds-media/images/cosine-similarity-vectors.original.jpg\" alt=\"NLP Gif\" style=\"width: 700px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoEMdNgQxYaU"
      },
      "source": [
        "<h2 style=\"color: #FF6347;\">Keyword Highlighting</h2>\n",
        "\n",
        "Highlighting important keywords helps users quickly understand the relevance of the retrieved text to their query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nCXL9Cz1xYaV"
      },
      "outputs": [],
      "source": [
        "from termcolor import colored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwDyofY0xYaV"
      },
      "source": [
        "The `highlight_keywords` function is designed to highlight specific keywords within a given text. It replaces each keyword in the text with a highlighted version using the `colored` function from the `termcolor` library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9y3E0YWExYaV"
      },
      "outputs": [],
      "source": [
        "def highlight_keywords(text, keywords):\n",
        "    for keyword in keywords:\n",
        "        text = text.replace(keyword, colored(keyword, 'green', attrs=['bold']))\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice4: add your keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "i7SkWPpnxYaW",
        "outputId": "28e82563-edba-4b41-acad-ec27e5ba134f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Snippet 1:\n",
            "\u001b[1m\u001b[32mArtificial Intelligence\u001b[0m (AI): When \u001b[1m\u001b[32mHuman\u001b[0ms and \u001b[1m\u001b[32mMachines\u001b[0m Might Have to Coexist   25\n",
            "These three laws already hint at the difficulty of \u001b[1m\u001b[32mhuman\u001b[0ms and \u001b[1m\u001b[32mrobot\u001b[0ms \u001b[1m\u001b[32mcoexist\u001b[0m -\n",
            "ing. In any case, the \u001b[1m\u001b[32mrobot\u001b[0m in Asimov’s\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "query_keywords = [\"machines\", \"Machines\", \"human\", \"Human\", \"Artificial Intelligence\", \"robot\", \"coexist\"] # add your keywords\n",
        "for i, doc in enumerate(retrieved_docs[:1]):\n",
        "    snippet = doc.page_content[:200]\n",
        "    highlighted = highlight_keywords(snippet, query_keywords)\n",
        "    print(f\"Snippet {i+1}:\\n{highlighted}\\n{'-'*80}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhV_Jf_LxYaX"
      },
      "source": [
        "1. `query_keywords` is a list of keywords to be highlighted.\n",
        "2. The loop iterates over the first document in retrieved_docs.\n",
        "3. For each document, a snippet of the first 200 characters is extracted.\n",
        "4. The highlight_keywords function is called to highlight the keywords in the snippet.\n",
        "5. The highlighted snippet is printed along with a separator line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBRKysAvxYaX"
      },
      "source": [
        "<h1 style=\"color: #FF6347;\">Bonus</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj25lCybxYaX"
      },
      "source": [
        "**Try loading one of your own PDF books and go through the steps again to explore how the pipeline works with your content**:\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
